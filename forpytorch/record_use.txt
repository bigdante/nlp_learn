123
#一个保存了固定字典和大小的简单查找表。这个模块常用来保存词嵌入和用下标检索它们。
# 模块的输入是一个下标的列表，输出是对应的词嵌入。相当于随机生成了一个tensor，可以把它看作一个查询表，其size为[num_embeddings，embedding_dim] 。
torch.nn.Embedding
# Pytorch里的LSTM单元接受的输入都必须是3维的张量(Tensors).每一维代表的意思不能弄错
torch.nn.LSTM
# 这是将tensors进行拼接，如果是多个值就是多个tensor
torch.cat(inputs)
#
nn.Sequential
#返回tensor的拷贝，返回的新tensor和原来的tensor具有同样的大小和数据类型。
tensor.clone()
#nonzero函数是numpy中用于得到数组array中非零元素的位置（数组索引）的函数
squeeze()
unsqueeze(0)

scatter_(input, dim, index, src)：将src中数据根据index中的索引按照dim的方向填进input。可以理解成放置元素或者修改元素

dim：沿着哪个维度进行索引
index：用来 scatter 的元素索引
src：用来 scatter 的源元素，可以是一个标量或一个张量

nn.ParameterList()查看参数，或者设置参数

首先，lambda 不用声明函数名，x为参数，：后面为函数体，然后tmp就是
tmp = filter(lambda x: x.requires_grad, maml.parameters())
Prod计算所有元素的乘积
num = sum(map(lambda x: np.prod(x.shape), tmp))


